---
title: "Selecting priors to power-scale and posterior quantities to check"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Selecting priors to power-scale and posterior quantities to check}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

# Introduction

This vignette presents a more in-depth example of using priorsense. It
demonstrates two different but related concepts: (1) selecting
different priors to power-scale, and (2) specifying which posterior
quantities to check the sensitivity of.

We will fit two different models on the same data set. The first is a
linear model, which has easily interpretable parameters.

The second includes splines and the parameters are not as easy to
interpret. The specific model is not important, as the general
principles apply for any model that has many parameters, correlated
parameters or uninterpretable parameters. This includes other models
with smooths, non-linear models, Gaussian processes and other more
complex models.

The features used here require `brms` version 2.22.11 or greater.

The main takeaways for this vignette are:

- prior tagging makes it possible to partition priors to make
  selective power-scaling easier
  
- in more complex models, it is often better to check the sensitivity
  of predictions or preditive measures rather than the parameters

```{r, message = FALSE}
library(brms)
library(priorsense)
library(posterior)

options(priorsense.plot_help_text = FALSE)
options(brms.backend = "rstan")
```

We use the `airquality` data set, and fit a model predicting the
amount of ozone based on the temperature.

```{r}
data(airquality)
aq <- na.omit(airquality)
```

# Linear model

We first fit a linear model, with some priors specified. For each of
the priors we add a `tag` as these will be used for selectively
power-scaling the priors.

```{r, message = FALSE}
fit_lin <- brm(
  formula = bf(Ozone ~ Temp),
  data = aq,
  family = gaussian(),
  prior = c(
    prior(normal(0, 5), class = "b", coef = "Temp", tag = "b"),
    prior(normal(0, 10), class = "sigma", tag = "sigma"),
    prior(normal(0, 100), class = "Intercept", tag = "intercept")
  )
)
```

We will work with the posterior draws, rather than the entire `brmsfit` object. This requires binding the `log_lik` to the draws object.
```{r}
post_draws_lin <- as_draws_df(fit_lin) |>
  bind_draws(log_lik_draws(fit_lin))
```

As the model is simple, and each parameter is directly interpretable,
we can perform the power-scaling sensitivity check directly on all the
parameters.

```{r}
powerscale_sensitivity(
  post_draws_lin
)
```

This indicates that when we power-scale all the priors, the posterior
of sigma is changing.

Instead of looking at the parameter posteriors, we can check the
sensitivity of predictions and predictive performance measures.

For predictions, we will focus on the predictions at the minimum,
median and maximum temperatures from the data.

For predictive performance measures, we will use Bayesian R2 and
log-score.

We first define a log-score function.

```{r}
logscore <- function(x) {
  as.matrix(rowSums(log_lik(x)))
}
```

And then bind the draws of the predictions and measures to the
posterior draws. For this we will use the `predictions_as_draws`
helper function provided by `priorsense` which transforms predictions
from `brms` to draws objects.

```{r}
post_draws_lin <- post_draws_lin |>
  bind_draws(
    predictions_as_draws(
      x = fit_lin,
      predict_fn = bayes_R2,
      prediction_names = "R2",
      summary = FALSE)
  ) |>
  bind_draws(
    predictions_as_draws(
      x = fit_lin,
      predict_fn = logscore,
      prediction_names = "logscore"
    )
  ) |>
  bind_draws(
    predictions_as_draws(
      x = fit_lin,
      predict_fn = posterior_epred,
      prediction_names = c("pred_minTemp", "pred_medianTemp", "pred_maxTemp"),
      newdata = data.frame(Temp = c(min(aq$Temp), median(aq$Temp), max(aq$Temp)))
    )
  )

powerscale_sensitivity(
  post_draws_lin
)
```

In this case, these predictive metrics do not appear to be sensitive
to power-scaling the prior. If we are focused on prediction, we might
not be concerned about the potential prior-data conflict for the sigma
parameter. However, as the model is simple and sigma is interpretable
we can continue investigation.

We can confirm that it is the sigma prior that is causing the possible
prior-data conflict, by using the `prior_selection` argument and
specifying the `tag` we defined when creating the priors.

```{r}
powerscale_sensitivity(
  post_draws_lin,
  prior_selection = "sigma"
)
```

And we can visualise the conflict.

```{r, message = F, warning = F, fig.width = 12, fig.height = 4}
powerscale_plot_dens(
  post_draws_lin,
  variable = "sigma",
  prior_selection = "sigma"
)
```

Here we can see that there is a tendency for the posterior of sigma to
shift closer to zero when the prior is strengthened (power-scaling
alpha > 1). In this case, we did not have strong prior information
that informed the prior, so we can consider a wider prior for sigma.


# Spline model

Next we extend our model by adding splines.

```{r}
fit_spline <- brm(
  formula = bf(Ozone ~ s(Temp) + s(Wind)),
  data = aq,
  family = gaussian(),
  prior = c(
    prior(normal(0, 5), class = "b", coef = "sTemp_1", tag = "b"),
    prior(normal(0, 10), class = "sds", coef = "s(Temp)", tag = "sds"),
    prior(normal(0, 10), class = "sigma", tag = "sigma"),
    prior(normal(0, 100), class = "Intercept", tag = "intercept")
  )
)
```

This model is more complex, so it is more important to focus on
checking the sensitivity of specific posterior quantities, rather than
all the parameters. Here we will focus on the Bayesian R2, the
log-score and the predictions at the minimum, median and maximum of
the observed temperature.


```{r}
post_draws_spline <- as_draws_df(fit_spline) |>
  bind_draws(log_lik_draws(fit_spline)) |>
  bind_draws(
    predictions_as_draws(
      x = fit_spline,
      predict_fn = bayes_R2,
      prediction_names = "R2", summary = FALSE)
  ) |>
    bind_draws(
      predictions_as_draws(
        x = fit_spline,
        predict_fn = logscore,
        prediction_names = "logscore")
    ) |>
    bind_draws(
      predictions_as_draws(
        x = fit_spline,
        predict_fn = posterior_epred,
        prediction_names = c("pred_minTemp", "pred_medianTemp", "pred_maxTemp"),
      newdata = data.frame(Temp = c(min(aq$Temp), median(aq$Temp), max(aq$Temp)), Wind = median(aq$Wind))
      )
    )
```

We start with power-scaling all priors, but only looking at the effect
on `R2` and `logscore` and the predictions.

```{r}
powerscale_sensitivity(
  post_draws_spline,
  variable = c("R2", "logscore", "pred_minTemp", "pred_medianTemp", "pred_maxTemp")
)
```

We see sensitivity in both measures and the prediction at the median
temperature. Next, we selectively power-scale different priors by
specifying the corresponding `tag` in `prior_selection`.

As this model introduced a prior on the `sds` term, we can start
there.

```{r}
powerscale_sensitivity(
  post_draws_spline,
  variable = c("R2", "logscore", "pred_minTemp", "pred_medianTemp", "pred_maxTemp"),
  prior_selection = "sds"
)
```

There is clear sensitivity to this prior.  We can check all the other
priors at once by providing a vector as the `prior_selection`
argument.

```{r}
powerscale_sensitivity(
  post_draws_spline,
  variable = c("R2", "logscore", "pred_minTemp", "pred_minTemp", "pred_maxTemp"),
  prior_selection = c("intercept", "sigma", "b")
)
```

We can visualise the effect of power-scaling the `sds` prior on the
posterior `R2`, `logscore` and the predictions. Here we visualise the
change in posterior mean and standard deviation.

```{r, message = F, warning = F, fig.width = 12, fig.height = 4}
powerscale_plot_quantities(
  post_draws_spline,
  div_measure = NULL,
  variable = c("R2", "logscore", "pred_minTemp", "pred_medianTemp", "pred_maxTemp"),
  prior_selection = "sds"
)
```

Although not extremely sensitive, there is a tendency for the
predictive performance measures to decrease as the prior is
strengthened, which indicates that we need to rethink the choice of
prior for the `sds` parameter.
